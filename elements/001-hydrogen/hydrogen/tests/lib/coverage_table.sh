#!/bin/bash

# Script: coverage_table.sh
# Purpose: Analyze gcov files to show detailed line-by-line coverage statistics using tables
# Usage: ./coverage_table.sh

# This script analyzes gcov files generated by Test 11 Unity tests and Test 99 coverage tests
# and displays the results in a formatted table using the tables executable.

# CHANGELOG
# 1.0.2 - Added MAGENTA color flag for files with >0 coverage but <50% coverage when >100 instrumented lines
# 1.0.1 - Added YELLOW color flag for files with no coverage in either test type
# 1.0.0 - Initial version

# Get script directory and project paths
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"
BUILD_DIR="$PROJECT_ROOT/build/unity/src"
COVERAGE_BUILD_DIR="$PROJECT_ROOT/build/coverage/src"
TABLES_EXE="$PROJECT_ROOT/tests/lib/tables"

# Source the coverage common functions for combined analysis
source "$SCRIPT_DIR/coverage-common.sh"

# Load .trial-ignore patterns for consistent filtering
TRIAL_IGNORE_PATTERNS=()
if [[ -f "$PROJECT_ROOT/.trial-ignore" ]]; then
    while IFS= read -r line; do
        # Skip comments and empty lines
        if [[ "$line" =~ ^[[:space:]]*# ]] || [[ -z "$line" ]]; then
            continue
        fi
        # Remove leading ./ if present and add pattern
        pattern="${line#./}"
        TRIAL_IGNORE_PATTERNS+=("$pattern")
    done < "$PROJECT_ROOT/.trial-ignore"
fi

# Function to check if a file should be ignored based on .trial-ignore
should_ignore_file() {
    local filename="$1"
    
    for pattern in "${TRIAL_IGNORE_PATTERNS[@]}"; do
        if [[ "$filename" == *"$pattern"* ]]; then
            return 0  # Should ignore
        fi
    done
    
    return 1  # Should not ignore
}

# Associative arrays to store coverage data from both directories
declare -A unity_covered_lines
declare -A unity_instrumented_lines
declare -A coverage_covered_lines
declare -A coverage_instrumented_lines
declare -A all_files

# Function to analyze a single gcov file and store data
analyze_gcov_file() {
    local gcov_file="$1"
    local coverage_type="$2"  # "unity" or "coverage"
    
    # Use the same awk parsing logic as the working test scripts
    local line_counts
    line_counts=$(awk '
        /^[[:space:]]*[0-9]+\*?:[[:space:]]*[0-9]+:/ { covered++; total++ }
        /^[[:space:]]*#####:[[:space:]]*[0-9]+\*?:/ { total++ }
        END { 
            if (total == "") total = 0
            if (covered == "") covered = 0
            print total "," covered 
        }
    ' "$gcov_file" 2>/dev/null)
    
    local instrumented_lines="${line_counts%,*}"
    local covered_lines="${line_counts#*,}"
    
    # Default to 0 if parsing failed
    instrumented_lines=${instrumented_lines:-0}
    covered_lines=${covered_lines:-0}
    
    # Skip files with no instrumented lines
    if [ "$instrumented_lines" -eq 0 ]; then
        return
    fi
    
    # Extract the relative path from the gcov file, preserving directory structure
    local display_path
    if [[ "$gcov_file" == *"/unity/src/"* ]]; then
        # Extract path after /unity/src/
        display_path="${gcov_file#*"/unity/src/"}"
        display_path="${display_path%.gcov}"
    elif [[ "$gcov_file" == *"/coverage/src/"* ]]; then
        # Extract path after /coverage/src/
        display_path="${gcov_file#*"/coverage/src/"}"
        display_path="${display_path%.gcov}"
    else
        # Fallback to basename
        display_path=$(basename "$gcov_file" .gcov)
    fi
    
    # Ensure it starts with src/
    if [[ "$display_path" != src/* ]]; then
        display_path="src/$display_path"
    fi
    
    # Store data in appropriate arrays
    all_files["$display_path"]=1
    if [[ "$coverage_type" == "unity" ]]; then
        unity_covered_lines["$display_path"]=$covered_lines
        unity_instrumented_lines["$display_path"]=$instrumented_lines
    else
        coverage_covered_lines["$display_path"]=$covered_lines
        coverage_instrumented_lines["$display_path"]=$instrumented_lines
    fi
}

# Function to collect and process gcov files from a directory
collect_gcov_files() {
    local build_dir="$1"
    local coverage_type="$2"
    local files_found=0
    
    declare -a valid_gcov_files=()
    
    if [ -d "$build_dir" ]; then
        while IFS= read -r -d '' gcov_file; do
            # Extract the source filename from the gcov file
            filename=$(basename "$gcov_file" .gcov)
            
            # Skip external libraries and test framework files
            if [[ "$filename" == "unity.c" ]] || \
               [[ "$filename" == "jansson"* ]] || \
               [[ "$filename" == "test_"* ]] || \
               [[ "$gcov_file" == *"/usr/include/"* ]]; then
                continue
            fi
            
            # Skip files that should be ignored based on .trial-ignore
            if should_ignore_file "$filename"; then
                continue
            fi
            
            valid_gcov_files+=("$gcov_file")
        done < <(find "$build_dir" -name "*.gcov" -type f -print0 2>/dev/null)
        
        # Sort the valid gcov files by filename and process them
        mapfile -t sorted_files < <(printf '%s\n' "${valid_gcov_files[@]}" | sort)
        
        for gcov_file in "${sorted_files[@]}"; do
            analyze_gcov_file "$gcov_file" "$coverage_type"
            ((files_found++))
        done
    fi
    
    return "$files_found"
}

# Collect data from Unity build directory
collect_gcov_files "$BUILD_DIR" "unity"
unity_files=$?

# Collect data from Coverage build directory  
collect_gcov_files "$COVERAGE_BUILD_DIR" "coverage"
coverage_files=$?

gcov_files_found=$((unity_files + coverage_files))

if [ "$gcov_files_found" -eq 0 ]; then
    echo "No gcov files found in either $BUILD_DIR or $COVERAGE_BUILD_DIR"
    echo "Make sure tests have been run first to generate coverage data."
    exit 1
fi

# Calculate combined coverage for each file using the new shared function
declare -A combined_covered_lines
declare -A combined_instrumented_lines

for file_path in "${!all_files[@]}"; do
    # Use the data we already have from individual analysis instead of re-finding files
    u_covered=${unity_covered_lines["$file_path"]:-0}
    u_instrumented=${unity_instrumented_lines["$file_path"]:-0}
    c_covered=${coverage_covered_lines["$file_path"]:-0}
    c_instrumented=${coverage_instrumented_lines["$file_path"]:-0}
    
    # For combined coverage: use max instrumented lines and max covered lines
    # This represents the union of coverage from both test suites
    max_instrumented=$((u_instrumented > c_instrumented ? u_instrumented : c_instrumented))
    max_covered=$((u_covered > c_covered ? u_covered : c_covered))
    
    combined_instrumented_lines["$file_path"]=$max_instrumented
    combined_covered_lines["$file_path"]=$max_covered
done

# Calculate totals for summary first
unity_total_covered=0
unity_total_instrumented=0
coverage_total_covered=0
coverage_total_instrumented=0
combined_total_covered=0
combined_total_instrumented=0

for file_path in "${!all_files[@]}"; do
    # Get Unity data
    u_covered=${unity_covered_lines["$file_path"]:-0}
    u_instrumented=${unity_instrumented_lines["$file_path"]:-0}
    
    # Get Coverage data
    c_covered=${coverage_covered_lines["$file_path"]:-0}
    c_instrumented=${coverage_instrumented_lines["$file_path"]:-0}
    
    # Get Combined data
    combined_covered=${combined_covered_lines["$file_path"]:-0}
    combined_instrumented=${combined_instrumented_lines["$file_path"]:-0}
    
    # Add to totals
    unity_total_covered=$((unity_total_covered + u_covered))
    unity_total_instrumented=$((unity_total_instrumented + u_instrumented))
    coverage_total_covered=$((coverage_total_covered + c_covered))
    coverage_total_instrumented=$((coverage_total_instrumented + c_instrumented))
    combined_total_covered=$((combined_total_covered + combined_covered))
    combined_total_instrumented=$((combined_total_instrumented + combined_instrumented))
done

# Calculate total percentages
unity_total_pct="0.000"
if [ "$unity_total_instrumented" -gt 0 ]; then
    unity_total_pct=$(awk "BEGIN {printf \"%.3f\", ($unity_total_covered / $unity_total_instrumented) * 100}")
fi

coverage_total_pct="0.000"
if [ "$coverage_total_instrumented" -gt 0 ]; then
    coverage_total_pct=$(awk "BEGIN {printf \"%.3f\", ($coverage_total_covered / $coverage_total_instrumented) * 100}")
fi

combined_total_pct="0.000"
if [ "$combined_total_instrumented" -gt 0 ]; then
    combined_total_pct=$(awk "BEGIN {printf \"%.3f\", ($combined_total_covered / $combined_total_instrumented) * 100}")
fi

# Store the combined coverage value for other scripts to use
echo "$combined_total_pct" > "$COMBINED_COVERAGE_FILE"

# Create temporary directory for JSON files
temp_dir=$(mktemp -d 2>/dev/null) || { echo "Error: Failed to create temporary directory"; exit 1; }
layout_json="$temp_dir/coverage_layout.json"
data_json="$temp_dir/coverage_data.json"
    
    # Create layout JSON for the coverage table (now with correct totals)
    cat > "$layout_json" << EOF
{
    "title": "Test Suite Coverage {NC}{RED}———{RESET}{BOLD} Unity: ${unity_total_pct}% {RESET}{RED}———{RESET}{BOLD} Blackbox: ${coverage_total_pct}% {RESET}{RED}———{RESET}{BOLD} Combined: ${combined_total_pct}%",
    "footer": "Generated: $(date)",
    "footer_position": "right",
    "theme": "Red",
    "columns": [
        {
            "header": "Folder",
            "key": "folder",
            "datatype": "text",
            "visible": false,
            "break": true
        },
        {
            "header": "Cover %",
            "key": "combined_coverage_percentage",
            "datatype": "float",
            "justification": "right"
        },
        {
            "header": "Lines",
            "key": "coverage_instrumented",
            "datatype": "int", 
            "justification": "right",
            "summary": "sum"
        },
        {
            "header": "Source File",
            "key": "file_path",
            "datatype": "text",
            "summary": "count",
            "width": 52
        },
        {
            "header": "Unity",
            "key": "unity_covered",
            "datatype": "int",
            "justification": "right",
            "summary": "sum",
            "width": 8
        },
        {
            "header": "Tests",
            "key": "coverage_covered",
            "datatype": "int",
            "justification": "right",
            "summary": "sum",
            "width": 8
        },
        {
            "header": "Cover",
            "key": "combined_covered",
            "datatype": "int",
            "justification": "right",
            "summary": "sum",
            "width": 8
        }
    ]
}
EOF

# Start the data JSON array
echo '[' > "$data_json"
first_record=true


# Create array for sorting by folder and file
declare -a file_data=()
for file_path in "${!all_files[@]}"; do
    # Extract folder name from file path using first two levels below src/
    folder="src/"
    if [[ "$file_path" == src/* ]]; then
        # Get the path after src/
        path_after_src="${file_path#src/}"
        if [[ "$path_after_src" == */* ]]; then
            # Has at least one subdirectory
            first_level="${path_after_src%%/*}"
            remaining_path="${path_after_src#*/}"
            
            if [[ "$remaining_path" == */* ]]; then
                # Has at least two subdirectories
                second_level="${remaining_path%%/*}"
                folder="src/${first_level}/${second_level}"
            else
                # Only one subdirectory level
                folder="src/${first_level}"
            fi
        else
            # File directly in src/
            folder="src/"
        fi
    fi
    
    # Store data with sort key: folder:filename
    file_data+=("$folder:$file_path")
done

# Sort by folder, then by filename, ensuring src/hydrogen.c appears first
mapfile -t sorted_file_data < <(printf '%s\n' "${file_data[@]}" | sort -t: -k1,1 -k2,2)

# Generate JSON data for tables
for file_data_entry in "${sorted_file_data[@]}"; do
    folder="${file_data_entry%%:*}"
    file_path="${file_data_entry#*:}"
    # Get Unity data
    u_covered=${unity_covered_lines["$file_path"]:-0}
    u_instrumented=${unity_instrumented_lines["$file_path"]:-0}
    u_percentage="0.000"
    if [ "$u_instrumented" -gt 0 ]; then
        u_percentage=$(awk "BEGIN {printf \"%.3f\", ($u_covered / $u_instrumented) * 100}")
    fi
    
    # Get Coverage data
    c_covered=${coverage_covered_lines["$file_path"]:-0}
    c_instrumented=${coverage_instrumented_lines["$file_path"]:-0}
    c_percentage="0.000"
    if [ "$c_instrumented" -gt 0 ]; then
        c_percentage=$(awk "BEGIN {printf \"%.3f\", ($c_covered / $c_instrumented) * 100}")
    fi
    
    # Get Combined data
    combined_covered=${combined_covered_lines["$file_path"]:-0}
    combined_instrumented=${combined_instrumented_lines["$file_path"]:-0}
    combined_percentage="0.000"
    if [ "$combined_instrumented" -gt 0 ]; then
        combined_percentage=$(awk "BEGIN {printf \"%.3f\", ($combined_covered / $combined_instrumented) * 100}")
    fi
    
    # Calculate maximum coverage percentage
    max_percentage=$(awk "BEGIN {
        u = $u_percentage
        c = $c_percentage
        if (u > c) print u; else print c
    }")
    
    # Highlight files with no coverage in either test type
    display_file_path="$file_path"
    if [[ $u_covered -eq 0 && $c_covered -eq 0 ]]; then
        display_file_path="{YELLOW}$file_path{RESET}"
    elif [[ $combined_covered -gt 0 && $combined_instrumented -gt 100 ]]; then
        # Check if coverage is less than 50%
        coverage_below_50=$(awk "BEGIN {print ($combined_percentage < 50.0) ? 1 : 0}")
        if [[ $coverage_below_50 -eq 1 ]]; then
            display_file_path="{MAGENTA}$file_path{RESET}"
        fi
    fi
    
    # Add comma before record if not first
    if [ "$first_record" = false ]; then
        echo '    ,' >> "$data_json"
    else
        first_record=false
    fi
    
    # Add JSON record with folder field and max coverage
    cat >> "$data_json" << EOF
    {
        "folder": "$folder",
        "max_coverage_percentage": $max_percentage,
        "combined_coverage_percentage": $combined_percentage,
        "file_path": "$display_file_path",
        "unity_covered": $u_covered,
        "unity_instrumented": $u_instrumented,
        "unity_percentage": $u_percentage,
        "coverage_covered": $c_covered,
        "coverage_instrumented": $c_instrumented,
        "coverage_percentage": $c_percentage,
        "combined_covered": $combined_covered,
        "combined_instrumented": $combined_instrumented
    }
EOF
done

# Close the JSON array
echo '' >> "$data_json"
echo ']' >> "$data_json"

# Use tables executable to render the table
"$TABLES_EXE" "$layout_json" "$data_json" 2>/dev/null || {
    echo "Error: Failed to run tables executable"
    exit 1
}

# Clean up temporary files
rm -rf "$temp_dir" 2>/dev/null
