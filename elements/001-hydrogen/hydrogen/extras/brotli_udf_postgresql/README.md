# Brotli Decompression Extension for PostgreSQL

This directory contains the PostgreSQL extension for Brotli decompression, used by the Helium migration system to decompress large base64-encoded strings.

## Files

- `brotli_decompress.c` - C implementation of Brotli decompression function
- `brotli_decompress.control` - Extension metadata
- `brotli_decompress--1.0.sql` - SQL function definition
- `Makefile` - Build and installation automation using PGXS
- `README.md` - This file

## Dependencies

- PostgreSQL 9.1 or later
- libbrotlidec (Brotli decompression library)
- postgresql-server-dev package (for postgres.h headers)
- gcc compiler

### Installing Dependencies

```bash
# Ubuntu/Debian
sudo apt-get install postgresql-server-dev-all libbrotli-dev

# RHEL/CentOS
sudo yum install postgresql-devel brotli-devel
```

## Building and Installing

```bash
# Build the extension
make

# Install to PostgreSQL (requires superuser)
sudo make install

# Enable in your database
psql -d yourdb -c "CREATE EXTENSION brotli_decompress;"
```

## Manual Testing of Encoded Strings

To verify that the base64 and Brotli encoding/decoding pipeline is working correctly, you can manually test encoded strings using command-line tools:

### Testing Base64 + Brotli Decompression

```bash
# Extract a base64-encoded compressed string from your migration data
# Then decode and decompress it manually:

echo "H4sIAAAAAAAA/0XOwQ2AIBAE0F8h..." | base64 -d | brotli -d

# Or using a file:
cat encoded_string.txt | base64 -d | brotli -d
```

### Testing Individual Components

```bash
# Test just base64 decoding:
echo "SGVsbG8gV29ybGQ=" | base64 -d
# Output: "Hello World"

# Test just brotli decompression:
echo "compressed_data" | brotli -d

# Test full pipeline (base64 decode then brotli decompress):
echo "base64_encoded_brotli_data" | base64 -d | brotli -d
```

### Verifying Migration Data

When debugging migration issues, you can extract the encoded strings from the database and verify them:

```sql
-- Get the encoded data from queries table
SELECT code FROM queries WHERE query_ref = 1000;
```

Then copy the base64 string and test it manually:

```bash
# Replace 'encoded_string_here' with actual data from database
echo "encoded_string_here" | base64 -d | brotli -d
```

This manual testing helps verify that:

- Base64 encoding/decoding is working correctly
- Brotli compression/decompression is functioning
- The data integrity is maintained through the full pipeline
- Migration scripts will produce the expected decompressed SQL

## Usage in Migrations

The extension is automatically used by migration 1000 when processing migrations with compressed strings larger than 1KB:

```sql
-- Example usage (generated automatically)
INSERT INTO queries (code) VALUES (
    brotli_decompress(CONVERT_FROM(DECODE('base64_encoded_compressed_data', 'base64'), 'UTF8'))
);
```

## Detailed Migration System Integration

The Brotli decompression extension integrates with PostgreSQL's native base64 and conversion functions.

### Automatic Extension Creation

Migration 1000 (`acuranzo_1000.lua`) creates the function using this SQL:

```sql
-- Generated by migration 1000
CREATE OR REPLACE FUNCTION ${SCHEMA}brotli_decompress(compressed bytea)
RETURNS text
AS 'brotli_decompress', 'brotli_decompress'
LANGUAGE C STRICT IMMUTABLE;
```

The extension must be installed in PostgreSQL's library directory before running migrations.

### Compression Pipeline

The migration system processes large strings through:

1. **Detection**: Identifies strings > 1KB in `[=[multiline blocks]=]`
2. **Compression**: Brotli compression (quality 11)
3. **Encoding**: Base64 encoding
4. **Storage**: PostgreSQL's `DECODE(..., 'base64')` and `CONVERT_FROM(..., 'UTF8')` handle decoding

### Generated SQL Examples

#### Compressed Migration Code

```sql
INSERT INTO queries (code) VALUES (
    ${SCHEMA}brotli_decompress(DECODE('H4sIAAAAAAAA/0XOwQ2AIBAE0F8h...', 'base64'))
);
```

#### Full Pipeline with Conversion

```sql
-- Complete generated pattern
${SCHEMA}brotli_decompress(CONVERT_FROM(DECODE('encoded_data', 'base64'), 'UTF8'))
```

### Migration Author Experience

Authors write standard SQL with multiline markers:

```lua
-- In migration file
sql=[[
    [=[
        CREATE TABLE products (
            id SERIAL PRIMARY KEY,
            name TEXT NOT NULL,
            -- ... extensive DDL
        );
    ]=]
]]
```

The system automatically handles compression and encoding.

## Function Signature

```sql
CREATE FUNCTION brotli_decompress(compressed bytea)
RETURNS text
LANGUAGE C STRICT IMMUTABLE;
```

## Troubleshooting

### Error: extension "brotli_decompress" is not available

Solution:

```bash
# Reinstall the extension
cd extras/brotli_udf_postgresql
sudo make install

# Verify installation
psql -c "SELECT name, default_version FROM pg_available_extensions WHERE name = 'brotli_decompress';"
```

### Error: could not load library

Solution:

```bash
# Check if libbrotlidec is installed
ldconfig -p | grep brotli

# If not found, install
sudo apt-get install libbrotli-dev
sudo ldconfig
```

### Error: permission denied

Solution:

```bash
# Ensure you have superuser privileges
psql -c "CREATE EXTENSION brotli_decompress;" -U postgres
```

## Integration with Migration System

This extension is declared in migration 1000 (`acuranzo_1000.lua`) using the function declaration SQL. The compression is transparent to migration authors - strings larger than 1KB are automatically compressed by the Lua migration system.

## Performance

- Native C implementation
- < 1ms decompression for most strings
- 70-80% size reduction for text content
- Minimal CPU overhead
- Example: 21KB CSS â†’ 5.9KB compressed+base64

## Version History

- 1.0.0 (2025-11-27) - Initial creation for Brotli decompression support